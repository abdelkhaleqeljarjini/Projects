{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-20T13:46:52.771303Z",
     "iopub.status.busy": "2025-10-20T13:46:52.771049Z",
     "iopub.status.idle": "2025-10-20T13:46:52.843319Z",
     "shell.execute_reply": "2025-10-20T13:46:52.838496Z",
     "shell.execute_reply.started": "2025-10-20T13:46:52.771276Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch_xla\n",
    "import torch_xla.core.xla_model as xm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-10-20T13:46:52.846581Z",
     "iopub.status.idle": "2025-10-20T13:46:52.846891Z",
     "shell.execute_reply": "2025-10-20T13:46:52.846748Z",
     "shell.execute_reply.started": "2025-10-20T13:46:52.846734Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import gc\n",
    "\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import transformers\n",
    "from transformers import BertTokenizer, BertForSequenceClassification \n",
    "from transformers import XLMRobertaTokenizer, XLMRobertaForSequenceClassification\n",
    "from torch.optim import AdamW\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **1. DataFrame loading**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-10-20T13:46:52.863799Z",
     "iopub.status.idle": "2025-10-20T13:46:52.864403Z",
     "shell.execute_reply": "2025-10-20T13:46:52.864244Z",
     "shell.execute_reply.started": "2025-10-20T13:46:52.864229Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-10-20T13:46:52.865007Z",
     "iopub.status.idle": "2025-10-20T13:46:52.865289Z",
     "shell.execute_reply": "2025-10-20T13:46:52.865156Z",
     "shell.execute_reply.started": "2025-10-20T13:46:52.865144Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-10-20T13:46:52.866689Z",
     "iopub.status.idle": "2025-10-20T13:46:52.867055Z",
     "shell.execute_reply": "2025-10-20T13:46:52.866915Z",
     "shell.execute_reply.started": "2025-10-20T13:46:52.866898Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test, y_train, y_test = train_test_split(df[['text','valence']], df[['valence']], \n",
    "                                                    test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-10-20T13:46:52.867894Z",
     "iopub.status.idle": "2025-10-20T13:46:52.868169Z",
     "shell.execute_reply": "2025-10-20T13:46:52.868035Z",
     "shell.execute_reply.started": "2025-10-20T13:46:52.868024Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-10-20T13:46:52.870286Z",
     "iopub.status.idle": "2025-10-20T13:46:52.870603Z",
     "shell.execute_reply": "2025-10-20T13:46:52.870463Z",
     "shell.execute_reply.started": "2025-10-20T13:46:52.870431Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "# initialize kfold\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=103)\n",
    "\n",
    "# for stratification\n",
    "y = train['valence']\n",
    "\n",
    "# Put the folds into a list. This is a list of tuples.\n",
    "fold_list = list(kf.split(train, y))\n",
    "\n",
    "ds_train_list = []\n",
    "ds_val_list = []\n",
    "for i, fold in enumerate(fold_list):\n",
    "    ds_train = train[train.index.isin(fold[0])]\n",
    "    ds_val = train[train.index.isin(fold[1])]\n",
    "    ds_train_list.append(ds_train)\n",
    "    ds_val_list.append(ds_val)\n",
    "    \n",
    "print(len(ds_train_list))\n",
    "print(len(ds_val_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-10-20T13:46:52.871380Z",
     "iopub.status.idle": "2025-10-20T13:46:52.871697Z",
     "shell.execute_reply": "2025-10-20T13:46:52.871550Z",
     "shell.execute_reply.started": "2025-10-20T13:46:52.871538Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "ds_train_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-10-20T13:46:52.872603Z",
     "iopub.status.idle": "2025-10-20T13:46:52.872901Z",
     "shell.execute_reply": "2025-10-20T13:46:52.872763Z",
     "shell.execute_reply.started": "2025-10-20T13:46:52.872750Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "ds_val_list[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. **Hyperparameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-10-20T13:46:52.874034Z",
     "iopub.status.idle": "2025-10-20T13:46:52.874331Z",
     "shell.execute_reply": "2025-10-20T13:46:52.874188Z",
     "shell.execute_reply.started": "2025-10-20T13:46:52.874176Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "MODEL_TYPE = 'bert-base-multilingual-uncased'\n",
    "\n",
    "NUM_FOLDS = 5\n",
    "\n",
    "NUM_FOLDS_TO_TRAIN = 3 \n",
    "\n",
    "L_RATE = 1e-6\n",
    "MAX_LEN = 300\n",
    "NUM_EPOCHS = 6\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "NUM_CORES = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-10-20T13:46:52.875674Z",
     "iopub.status.idle": "2025-10-20T13:46:52.875966Z",
     "shell.execute_reply": "2025-10-20T13:46:52.875830Z",
     "shell.execute_reply.started": "2025-10-20T13:46:52.875817Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#Device depending on availability in kaggle\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device=\"cpu\"\n",
    "print(device)\n",
    "\n",
    "# device = xm.xla_device()\n",
    "# print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-10-20T13:46:52.877550Z",
     "iopub.status.idle": "2025-10-20T13:46:52.877849Z",
     "shell.execute_reply": "2025-10-20T13:46:52.877708Z",
     "shell.execute_reply.started": "2025-10-20T13:46:52.877696Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#Initializing Bert Tokenizer\n",
    "from transformers import AutoTokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(MODEL_TYPE,do_lower_case=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-10-20T13:46:52.880605Z",
     "iopub.status.idle": "2025-10-20T13:46:52.881000Z",
     "shell.execute_reply": "2025-10-20T13:46:52.880768Z",
     "shell.execute_reply.started": "2025-10-20T13:46:52.880755Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#Data Loader using torch Dataset and DataLoader\n",
    "class TrainDataset(Dataset):\n",
    "\n",
    "    def __init__(self,dataframe):\n",
    "        self.df = dataframe\n",
    "\n",
    "    def __getitem__(self,index):\n",
    "\n",
    "        text = self.df.loc[index,'text']\n",
    "        #tokenizing the data\n",
    "        encoded_dict = tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length = MAX_LEN,\n",
    "            return_attention_mask=True,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        #Extracting the model inputs, already tensors\n",
    "        padded_tokens_list = encoded_dict['input_ids'].squeeze()\n",
    "        att_mask = encoded_dict['attention_mask'].squeeze()\n",
    "        token_type_ids = encoded_dict['token_type_ids'].squeeze()\n",
    "        #transforming target label to tensors\n",
    "        # target = self.df.loc[index,'valence']\n",
    "        target = torch.tensor(self.df.loc[index,'valence'],dtype=torch.float32)\n",
    "        sample = (padded_tokens_list,att_mask,token_type_ids,target)\n",
    "        return sample\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "class TestDataset(Dataset):\n",
    "\n",
    "    def __init__(self,df):\n",
    "        self.df = df\n",
    "\n",
    "    def __getitem__(self,index):\n",
    "        text = self.df.loc[index,'text']\n",
    "        #tokenizing the data\n",
    "        encoded_dict = tokenizer.encpde_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length = MAX_LEN,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors = 'pt',\n",
    "            truncation=True,\n",
    "            padding='max_length'\n",
    "        )\n",
    "        #Extracting the model inputs, already tensors\n",
    "        padded_tokens_list = encoded_dict['input_ids'].squeeze()\n",
    "        att_mask = encoded_dict['attention_mask'].squeeze()\n",
    "        token_type_ids = encoded_dict['token_type_ids'].squeeze()\n",
    "        sample = (padded_tokens_list,att_mask,token_type_ids)\n",
    "        return sample\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-10-20T13:46:52.881732Z",
     "iopub.status.idle": "2025-10-20T13:46:52.882023Z",
     "shell.execute_reply": "2025-10-20T13:46:52.881886Z",
     "shell.execute_reply.started": "2025-10-20T13:46:52.881873Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# First we will train only with one fold, experimenting on model parameters and architecture.\n",
    "fold_train = ds_train_list[0].reset_index(drop=True)\n",
    "fold_val = ds_val_list[0].reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-10-20T13:46:52.886057Z",
     "iopub.status.idle": "2025-10-20T13:46:52.886351Z",
     "shell.execute_reply": "2025-10-20T13:46:52.886209Z",
     "shell.execute_reply.started": "2025-10-20T13:46:52.886195Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#Checking the dataloader\n",
    "fold_dst = TrainDataset(fold_train)\n",
    "fold_dsv= TrainDataset(fold_val)\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    fold_dst,batch_size=BATCH_SIZE,shuffle=True,num_workers=NUM_CORES\n",
    ")\n",
    "val_dataloader = torch.utils.data.DataLoader(\n",
    "    fold_dsv,batch_size=BATCH_SIZE,shuffle=True,num_workers=NUM_CORES, drop_last=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-10-20T13:46:52.887404Z",
     "iopub.status.idle": "2025-10-20T13:46:52.887708Z",
     "shell.execute_reply": "2025-10-20T13:46:52.887572Z",
     "shell.execute_reply.started": "2025-10-20T13:46:52.887559Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(len(train_dataloader))\n",
    "print(len(val_dataloader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **5. Regression Head**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-10-20T13:46:52.900175Z",
     "iopub.status.idle": "2025-10-20T13:46:52.900595Z",
     "shell.execute_reply": "2025-10-20T13:46:52.900483Z",
     "shell.execute_reply.started": "2025-10-20T13:46:52.900466Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import BertPreTrainedModel\n",
    "from transformers import BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-10-20T13:46:52.901732Z",
     "iopub.status.idle": "2025-10-20T13:46:52.902056Z",
     "shell.execute_reply": "2025-10-20T13:46:52.901955Z",
     "shell.execute_reply.started": "2025-10-20T13:46:52.901943Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# we want predict numerical values of sentiments, we build a regression head over the BertModel\n",
    "class RegressionLayer(BertPreTrainedModel):\n",
    "\n",
    "    def __init__(self,confg):\n",
    "        super().__init__(confg)\n",
    "        self.bert=BertModel(confg)\n",
    "        self.regressor = nn.Linear(confg.hidden_size,1)\n",
    "        self.init_weights() #initializing weights for the whole model\n",
    "\n",
    "#defining the forward pass, returns the MSE loss and logits which only one value per sample.\n",
    "    def forward(self,input_ids=None,attention_mask=None,labels=None, token_type_ids=None):\n",
    "        outputs = self.bert(input_ids=input_ids,attention_mask=attention_mask,\n",
    "                            token_type_ids=token_type_ids)\n",
    "        pooled_output = outputs.pooler_output\n",
    "        logits = self.regressor(pooled_output)\n",
    "        last_hidden_state = outputs.last_hidden_state\n",
    "        \n",
    "        loss= None\n",
    "        if labels is not None:\n",
    "            loss=nn.MSELoss()(logits.view(-1),labels.view(-1))\n",
    "        return {'loss':loss,'logits':logits, 'last_hidden_state':last_hidden_state}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-10-20T13:46:52.903246Z",
     "iopub.status.idle": "2025-10-20T13:46:52.903506Z",
     "shell.execute_reply": "2025-10-20T13:46:52.903373Z",
     "shell.execute_reply.started": "2025-10-20T13:46:52.903361Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#initilizing the model\n",
    "model = RegressionLayer.from_pretrained(MODEL_TYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-10-20T13:46:52.906206Z",
     "iopub.status.idle": "2025-10-20T13:46:52.906557Z",
     "shell.execute_reply": "2025-10-20T13:46:52.906410Z",
     "shell.execute_reply.started": "2025-10-20T13:46:52.906393Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#For memory usage tracking\n",
    "import psutil, os\n",
    "\n",
    "def memory_usage():\n",
    "    mem = psutil.Process(os.getpid()).memory_info().rss / 1024**3\n",
    "    print(f\"Memory usage: {mem:.2f} GB\")\n",
    "\n",
    "memory_usage()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.Training the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-20T12:42:21.568028Z",
     "iopub.status.busy": "2025-10-20T12:42:21.567748Z",
     "iopub.status.idle": "2025-10-20T12:47:50.912096Z",
     "shell.execute_reply": "2025-10-20T12:47:50.911237Z",
     "shell.execute_reply.started": "2025-10-20T12:42:21.568007Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "seed_val = 1024\n",
    "\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "#traing on 1 fold for experiments\n",
    "fold_train = ds_train_list[0].reset_index(drop=True)\n",
    "fold_val = ds_val_list[0].reset_index(drop=True)\n",
    "\n",
    "#calling our dataset class\n",
    "train_dataset = TrainDataset(fold_train)\n",
    "val_dataset = TrainDataset(fold_val)\n",
    "\n",
    "#Saving the MSE for each epoch\n",
    "epoch_val_mse=[]\n",
    "#Tracking epochs without improvement on validation dataset\n",
    "epochs_without_improvement = 0\n",
    "epoch=0\n",
    "\n",
    "#If in 3 consecutive epochs, no improvement on validation data, the algorithm will stop\n",
    "while epochs_without_improvement<3 and epoch<NUM_EPOCHS:\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch+1, NUM_EPOCHS))\n",
    "\n",
    "    if epoch==0:\n",
    "        model.to(device)\n",
    "        optimizer = AdamW(model.parameters(),\n",
    "                         lr=L_RATE,\n",
    "                         eps=1e-8)\n",
    "    else:\n",
    "        #For every epoch>0 we will use the weights of the last epoch to initialize the model's weights of the current epoch.\n",
    "        model_path = 'model_epoch'+'.bin'\n",
    "        model.load_state_dict(torch.load(model_path))\n",
    "        model.to(device)\n",
    "    #Calling dataloader\n",
    "    train_dataloader = torch.utils.data.DataLoader(train_dataset,batch_size=BATCH_SIZE,\n",
    "                                               shuffle=True,num_workers=NUM_CORES)\n",
    "    val_dataloader = torch.utils.data.DataLoader(val_dataset,batch_size=BATCH_SIZE,\n",
    "                                               shuffle=True,num_workers=NUM_CORES)\n",
    "    print('Training...')\n",
    "    model.train()\n",
    "    torch.set_grad_enabled(True)\n",
    "    total_train_loss = 0\n",
    "    \n",
    "    for i, batch in enumerate(train_dataloader):\n",
    "        \n",
    "        print('Batch '+str(i+1)+'/'+str(len(train_dataloader)),end='\\r')\n",
    "        input_ids = batch[0].to(device)\n",
    "        attention_mask = batch[1].to(device)\n",
    "        token_type_ids = batch[2].to(device)\n",
    "        labels = batch[3].to(device)\n",
    "        \n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            labels=labels)\n",
    "        \n",
    "        loss = outputs['loss']\n",
    "        total_train_loss +=loss.item()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(),1.0)\n",
    "        optimizer.step()\n",
    "        # xm.optimizer_step(optimizer, barrier=True)\n",
    "        # del input_ids, attention_mask, token_type_ids, labels\n",
    "        # gc.collect()\n",
    "        print('Train loss epoch '+str(epoch+1) +' :',total_train_loss)\n",
    "        print(torch.isnan(outputs['last_hidden_state']).any())\n",
    "        print(torch.isnan(outputs['logits']).any())\n",
    "        # print(torch.isnan(targets).any())\n",
    "    print('Validation...')\n",
    "    gc.collect()\n",
    "    torch.set_grad_enabled(False)\n",
    "    model.eval()\n",
    "    total_val_loss = 0\n",
    "    labels_list=[]\n",
    "    preds_list=[]\n",
    "    for j,val_batch in enumerate(val_dataloader):\n",
    "\n",
    "        input_ids = val_batch[0].to(device)\n",
    "        attention_mask = val_batch[1].to(device)\n",
    "        token_type_ids = val_batch[2].to(device)\n",
    "        labels = val_batch[3].to(device)\n",
    "        \n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            labels=labels)\n",
    "        loss = outputs['loss']\n",
    "        total_val_loss +=loss.item()\n",
    "        val_preds = outputs['logits'].detach().cpu().numpy()\n",
    "        val_labels = labels.detach().cpu().numpy()\n",
    "        labels_list.extend(val_labels)\n",
    "        preds_list.extend(val_preds)\n",
    "        # del input_ids, attention_mask, token_type_ids, labels\n",
    "        # gc.collect()\n",
    "        \n",
    "    MSE = mean_squared_error(labels_list, preds_list) #squared=False\n",
    "    \n",
    "    print('MSE: ',MSE)\n",
    "    print('val_loss',total_val_loss)\n",
    "\n",
    "    if epoch==0:\n",
    "        model_name = 'model_epoch'+'.bin'\n",
    "        torch.save(model.state_dict(), model_name)\n",
    "        print('Saved model as ', model_name)\n",
    "    else:\n",
    "        if MSE<min(epoch_val_mse):\n",
    "            model_name = 'model_epoch'+'.bin'\n",
    "            torch.save(model.state_dict(), model_name)\n",
    "            print('Val accuracy improved,saved model as ', model_name)\n",
    "            epochs_without_improvement=0\n",
    "        else:\n",
    "            epochs_without_improvement+=1\n",
    "            print('Val accuracy not improved, total epochs without improvement ', \n",
    "                  epochs_without_improvement)\n",
    "    epoch_val_mse.append(MSE)\n",
    "    epoch+=1\n",
    "    # gc.collect()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-20T13:45:53.816831Z",
     "iopub.status.busy": "2025-10-20T13:45:53.816552Z",
     "iopub.status.idle": "2025-10-20T13:45:53.837726Z",
     "shell.execute_reply": "2025-10-20T13:45:53.836849Z",
     "shell.execute_reply.started": "2025-10-20T13:45:53.816811Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "epoch_val_mse"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 8359730,
     "sourceId": 13191418,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
